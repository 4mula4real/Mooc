{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • The Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.What types of Machine Learning, if any, best describe the following three scenarios:\n",
    "(i) A coin classification system is created for a vending machine. The developers obtain exact coin specifications from the U.S. Mint and derive a statistical model of the size, weight, and denomination, which the vending machine then uses to classify coins.\n",
    "\n",
    "(ii) Instead of calling the U.S. Mint to obtain coin information, an algorithm is presented with a large set of labeled coins. The algorithm uses this data to infer decision boundaries which the vending machine then uses to classify its coins.\n",
    "\n",
    "(iii) A computer develops a strategy for playing Tic-Tac-Toe by playing repeatedly and adjusting its strategy by penalizing moves that eventually lead to losing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[a] (i) Supervised Learning, (ii) Unsupervised Learning, (iii) Reinforcement Learning\n",
    "\n",
    "[b] (i) Supervised Learning, (ii) Not learning, (iii) Unsupervised Learning\n",
    "\n",
    "[c] (i) Not learning, (ii) Reinforcement Learning, (iii) Supervised Learning\n",
    "\n",
    "[d] (i) Not learning, (ii) Supervised Learning, (iii) Reinforcement Learning\n",
    "\n",
    "[e] (i) Supervised Learning, (ii) Reinforcement Learning, (iii) Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [d]\n",
    "- i: The target function(y) is given.\n",
    "- ii: The data is labelled(correct output).\n",
    "- iii: The output is graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Which of the following problems are best suited for Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Classifying numbers into primes and non-primes.\n",
    "\n",
    "(ii) Detecting potential fraud in credit card charges.\n",
    "\n",
    "(iii) Determining the time it would take a falling object to hit the ground.\n",
    "\n",
    "(iv) Determining the optimal cycle for traffic lights in a busy intersection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[a] (ii) and (iv)\n",
    "\n",
    "[b] (i) and (ii)\n",
    "\n",
    "[c] (i), (ii), and (iii)\n",
    "\n",
    "[d] (iii)\n",
    "\n",
    "[e] (i) and (iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [a]\n",
    "- i and iii: Both has a analytical solution(do it mathematically)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • Bins and Marbles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. We have 2 opaque bags, each containing 2 balls. One bag has 2 black balls and the other has a black ball and a white ball. You pick a bag at random and then pick one of the balls in that bag at random. When you look at the ball, it is black. You now pick the second ball from that same bag. What is the probability that this ball is also black?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[a] 1/4\n",
    "\n",
    "[b] 1/3\n",
    "\n",
    "[c] 1/2\n",
    "\n",
    "[d] 2/3\n",
    "\n",
    "[e] 3/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [d]\n",
    "\n",
    "Approach 1: Classic\n",
    "\n",
    "There are four condition:\n",
    "\n",
    "Pick first bag: \n",
    "1. Black1 Black2\n",
    "2. Black2 Black1\n",
    "\n",
    "Pick second bag: \n",
    "3. Black1 White1\n",
    "4. White1 Black1(which is impossible)\n",
    "\n",
    "Probability = 2/3\n",
    "\n",
    "\n",
    "Approach 2: Bayes\n",
    "P(A∩B) = P(A|B) × P(B)= P(B|A) × P(A)\n",
    "\n",
    "- P(A) = First is black = 1/2 * 1/2 + 1/2 * 1 = 3/4\n",
    "- P(A∩B) =  First and second = 1/2\n",
    "- P(B|A) = When first is black, second is black = P(A and B)/P(A) = (1/2)/(3/4) = 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider a sample of 10 marbles drawn from a bin containing red and green marbles. The probability that any marble we draw is red is µ = 0.55 (independently, with replacement). We address the probability of getting no red marbles (ν = 0) in the following cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. We draw only one such sample. Compute the probability that ν = 0. \n",
    "The closest answer is (‘closest answer’ means: |your answer − given option| is closest to 0):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[a] 7.331 × 10 − 6\n",
    "\n",
    "[b] 3.405 × 10 − 4\n",
    "\n",
    "[c] 0.289\n",
    "\n",
    "[d] 0.450\n",
    "\n",
    "[e] 0.550"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.405063e-04\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10\n",
    "p_red = 0.55\n",
    "one_sample = (1- p_red) ** sample_size ## no red \n",
    "print(\"%e\" % one_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. We draw 1,000 independent samples. Compute the probability that (at least) one of the samples has ν = 0. The closest answer is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[a] 7.331 × 10 − 6\n",
    "\n",
    "[b] 3.405 × 10 − 4\n",
    "\n",
    "[c] 0.289\n",
    "\n",
    "[d] 0.450\n",
    "\n",
    "[e] 0.550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28863119784980995\n"
     ]
    }
   ],
   "source": [
    "sample_times = 1000\n",
    "p_no_red = (1 - one_sample) ** sample_times ## not no red\n",
    "print(1 - p_no_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • Feasibility of Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "Because of the data to prodict is only 3 and the data is belong to either 0 or 1, the possible space of target function is only $2^3 = 8$. \n",
    "Note that hypothesis is a way to approximate the target function.\n",
    "\n",
    "When Yaser explained this question, he said \"The message of this problem is that regardless of whether you are doing something intelligent or otherwise, there is noting that can be learned outside the training sample in a deterministic sense. To make the message crisp, the problem considers some 'crazy' training schemes in the mix.\" and \"The idea is that, outside the training set, no \"learning\" is possible if we take a deterministic view. This is a formal version of the puzzle given at the end of Lecture 1.\"\n",
    "\n",
    "My understanding is what learning is to \"learn\" from the data and make generalization to the population or out-sample data. And what we do is to make inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • The Perceptron Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(n, d = 2):\n",
    "    \"\"\"\n",
    "    generate a dataset from space X = [−1, 1] × [−1, 1]\n",
    "    \"\"\"\n",
    "    x0 = np.ones((n,1))\n",
    "    x = np.random.uniform(-1, 1, (n, d))\n",
    "    return np.hstack([x0, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pla(dataset):\n",
    "    \"\"\"\n",
    "    pla as Perceptron Learning Algorithm\n",
    "    \"\"\"\n",
    "    point1, point2 = np.random.uniform(-1, 1, (2,2))\n",
    "    interval = point1 - point2\n",
    "    gradient = interval[1] / interval[0]\n",
    "    bias = point1[1] - point1[0] * gradient\n",
    "    #  w0 + w1*x1 + w2*x2 = 0\n",
    "    target_weight = np.matrix([bias, gradient, -1]).T\n",
    "    y = np.sign(dataset * target_weight) # wT*x\n",
    "    # initial the weight\n",
    "    weight = np.matrix([0.0, 0.0, 0.0]).T\n",
    "    h = np.sign(dataset * weight) # wT*x\n",
    "    nums_iter = 0\n",
    "    while any(h != y):\n",
    "        misclassified = np.nonzero(h != y) # np.where, np.argwhere\n",
    "        mis_idx = np.random.choice(misclassified[0])\n",
    "        weight = (weight.T + y[mis_idx] * dataset[mis_idx]).T\n",
    "        nums_iter += 1\n",
    "        h = np.sign(dataset * weight)\n",
    "    \n",
    "    NUMS_TEST = 1000\n",
    "    test_data = gen_dataset(NUMS_TEST, d = 2)\n",
    "    y_test = np.sign(test_data * target_weight)\n",
    "    h_test = np.sign(test_data * weight)\n",
    "    disagreement = np.argwhere(y_test != h_test)\n",
    "    disagree_prob = len(disagreement) / NUMS_TEST\n",
    "    return nums_iter, disagree_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simu_pla(dataset):\n",
    "    \"\"\"\n",
    "    a simulation of Perceptron Learning Algorithm\n",
    "    \"\"\"\n",
    "    RUNS = 1000\n",
    "    nums_iter = 0\n",
    "    disagreement = 0\n",
    "    for _ in range(RUNS):\n",
    "        nums_iter += pla(dataset)[0]\n",
    "        disagreement += pla(dataset)[1]\n",
    "    return nums_iter/RUNS, disagreement/RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.978, 0.10575699999999996)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data10 = gen_dataset(10, d = 2)\n",
    "simu_pla(data10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102.254, 0.013350999999999972)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data100 = gen_dataset(100, d = 2)\n",
    "simu_pla(data100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
